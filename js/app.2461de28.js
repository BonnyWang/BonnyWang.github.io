(function(e){function t(t){for(var a,i,c=t[0],s=t[1],l=t[2],u=0,d=[];u<c.length;u++)i=c[u],Object.prototype.hasOwnProperty.call(n,i)&&n[i]&&d.push(n[i][0]),n[i]=0;for(a in s)Object.prototype.hasOwnProperty.call(s,a)&&(e[a]=s[a]);h&&h(t);while(d.length)d.shift()();return r.push.apply(r,l||[]),o()}function o(){for(var e,t=0;t<r.length;t++){for(var o=r[t],a=!0,c=1;c<o.length;c++){var s=o[c];0!==n[s]&&(a=!1)}a&&(r.splice(t--,1),e=i(i.s=o[0]))}return e}var a={},n={app:0},r=[];function i(t){if(a[t])return a[t].exports;var o=a[t]={i:t,l:!1,exports:{}};return e[t].call(o.exports,o,o.exports,i),o.l=!0,o.exports}i.m=e,i.c=a,i.d=function(e,t,o){i.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:o})},i.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.t=function(e,t){if(1&t&&(e=i(e)),8&t)return e;if(4&t&&"object"===typeof e&&e&&e.__esModule)return e;var o=Object.create(null);if(i.r(o),Object.defineProperty(o,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var a in e)i.d(o,a,function(t){return e[t]}.bind(null,a));return o},i.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return i.d(t,"a",t),t},i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},i.p="/";var c=window["webpackJsonp"]=window["webpackJsonp"]||[],s=c.push.bind(c);c.push=t,c=c.slice();for(var l=0;l<c.length;l++)t(c[l]);var h=s;r.push([0,"chunk-vendors"]),o()})({0:function(e,t,o){e.exports=o("56d7")},"00c2":function(e,t,o){"use strict";o("0d02")},"01f1":function(e,t,o){"use strict";o("db90")},"0d02":function(e,t,o){},"1c1c":function(e,t,o){"use strict";o("7387")},2982:function(e,t,o){"use strict";o("2ed1")},"2ed1":function(e,t,o){},"2ed4":function(e,t,o){"use strict";o("63cd")},"49a7":function(e,t,o){},"56d7":function(e,t,o){"use strict";o.r(t);o("e260"),o("e6cf"),o("cca6"),o("a79d"),o("ac1f"),o("5319");var a=o("7a23"),n={id:"mainHolder"},r={key:0,id:"Welcome"},i={key:1},c={key:1,id:"mainView"},s={id:"Navigation"},l=Object(a["h"])("h1",{id:"siteTitle"},"WELCOME",-1),h=Object(a["j"])("About Me"),u=Object(a["j"])("Projects"),d=Object(a["j"])("Gallery"),p={ref:"mbgm",controls:"",autoplay:"",loop:"",hidden:"true"},b=Object(a["h"])("source",{src:"/bgm.wav"},null,-1),m=Object(a["j"])(" Your browser does not support the audio element. "),g=[b,m];function f(e,t,o,b,m,f){var j=Object(a["A"])("router-link"),y=Object(a["A"])("router-view");return Object(a["t"])(),Object(a["g"])("div",n,[e.firstEnter?(Object(a["t"])(),Object(a["g"])("section",r,[e.loaded?(Object(a["t"])(),Object(a["g"])("button",{key:0,id:"Enter",onClick:t[0]||(t[0]=function(){return f.toMyWorld&&f.toMyWorld.apply(f,arguments)})},"↓ Enter My World ↓ ")):Object(a["f"])("",!0),e.loaded?Object(a["f"])("",!0):(Object(a["t"])(),Object(a["g"])("h2",i," loading "+Object(a["D"])(e.loadingProgress)+" % ",1))])):Object(a["f"])("",!0),e.loaded?(Object(a["t"])(),Object(a["g"])("section",c,[Object(a["h"])("button",{onClick:t[1]||(t[1]=function(){return f.playMusic&&f.playMusic.apply(f,arguments)}),ref:"playB",id:"playBgm"},null,512),Object(a["h"])("span",s,[l,Object(a["k"])(j,{to:"/AboutMe",id:"NavButton"},{default:Object(a["G"])((function(){return[h]})),_:1}),Object(a["k"])(j,{to:"/Projects",id:"NavButton"},{default:Object(a["G"])((function(){return[u]})),_:1}),Object(a["k"])(j,{to:"/Gallery",id:"NavButton"},{default:Object(a["G"])((function(){return[d]})),_:1})]),Object(a["k"])(y,null,{default:Object(a["G"])((function(e){var t=e.Component;return[Object(a["k"])(a["b"],{name:"fade",mode:"out-in"},{default:Object(a["G"])((function(){return[(Object(a["t"])(),Object(a["e"])(Object(a["B"])(t)))]})),_:2},1024)]})),_:1})])):Object(a["f"])("",!0),Object(a["h"])("audio",p,g,512)])}o("d3b7"),o("cfc3"),o("9a8c"),o("a975"),o("735e"),o("c1ac"),o("d139"),o("3a7b"),o("d5d6"),o("82f8"),o("e91f"),o("60bd"),o("5f96"),o("3280"),o("3fcc"),o("ca91"),o("25a1"),o("cd26"),o("3c5d"),o("2954"),o("649e"),o("219c"),o("170b"),o("b39a"),o("72f7"),o("159b");var j=o("5a89"),y=o("34ad"),w="/models/",v=new j["cb"];v.background=new j["k"](1184274);var O=new j["T"](75,window.innerWidth/window.innerHeight,.1,1e3),k=new j["pb"]({alpha:!0}),T=new j["p"];v.add(T),T.add(O);var I=new j["a"](16777215,.75),P=new j["U"](16777215,110,10);P.position.z=10,v.add(I),v.add(P),P.castShadow=!0;var C={width:window.innerWidth,height:window.innerHeight};window.addEventListener("resize",(function(){C.width=window.innerWidth,C.height=window.innerHeight,O.aspect=C.width/C.height,O.updateProjectionMatrix(),k.setSize(C.width,C.height),k.setPixelRatio(Math.min(window.devicePixelRatio,2))}));for(var A=200,x=new Float32Array(3*A),S=0;S<A;S++)x[3*S+0]=10*(Math.random()-.5),x[3*S+1]=10*(Math.random()-.5),x[3*S+2]=10*(Math.random()-.5);var N=new j["W"]({color:"#212121",sizeAttenuation:!0,size:.05}),G=new j["h"];G.setAttribute("position",new j["g"](x,3));var D=new j["V"](G,N);v.add(D);var W=new j["f"](1,1,1),E=new j["L"]({color:16711680}),M=new j["I"](W,E);v.add(M);var V,z=4,_=0,Y=0,R=0,L=0,B=0;function U(){var e=new y["a"];e.load(w+"/cutie.glb",(function(e){V=e.scene,V.position.z=-1,V.scale.x=.4,V.scale.y=.4,V.scale.z=.4,v.add(V),X()}),(function(e){var t=e.loaded/e.total;M.scale.x=2*t,M.scale.z=2*t,M.scale.y=2*t,Y=100*t,ar.loadingProgress=(Y+R+L+B)/4,console.log(t+"% loaded")}),(function(e){console.error(e)}))}var F,H,q,$=[];function J(){var e=new y["a"];e.load(w+"/realAsteroid.glb",(function(e){e.scene.scale.x=.5,e.scene.scale.y=.5,e.scene.scale.z=.5,$[0]=e.scene,$[1]=e.scene.clone(),v.add($[0]),v.add($[1]),$[0].position.x=-5,$[1].position.x=5,X()}),(function(e){var t=e.loaded/e.total;M.scale.x=2*t,M.scale.z=2*t,M.scale.y=2*t,L=100*t,ar.loadingProgress=(Y+R+L+B)/4,console.log(t+"% loaded")}),(function(e){console.error(e)}))}function Z(){var e=new y["a"];e.load(w+"/asteroidBonny.glb",(function(e){F=e.scene,F.scale.x=1,F.scale.y=1,F.scale.z=1,v.add(F),F.rotation.y-=.8,F.rotation.z+=.1,console.log(F),H=new j["c"](e.scene),e.animations.forEach((function(e){H.clipAction(e).play()})),X()}),(function(e){var t=e.loaded/e.total;M.scale.x=2*t,M.scale.z=2*t,M.scale.y=2*t,R=100*t,ar.loadingProgress=(Y+R+L+B)/4,console.log(t+"% loaded")}),(function(e){console.error(e)}))}function Q(){var e=new y["a"];e.load(w+"/asteroidBonnyFraction.glb",(function(e){q=e.scene,q.scale.x=.2,q.scale.y=.2,q.scale.z=.2,q.position.y=2,X()}),(function(e){var t=e.loaded/e.total;M.scale.x=2*t,M.scale.z=2*t,M.scale.y=2*t,B=100*t,ar.loadingProgress=(Y+R+L+B)/4,console.log(t+"% loaded")}),(function(e){console.error(e)}))}function X(){_++,_==z&&(console.log("All models loaded"),cancelAnimationFrame(ne),v.remove(M),ar.loaded=!0,he(),te(),ue(),"/"!=ar.checkRouteName()&&fe())}var K,ee=new j["j"];function te(){K=requestAnimationFrame(te),F.rotation.y+=.01;var e=ee.getDelta();F.position.y+=.01,F.position.y>2&&cancelAnimationFrame(K),H&&H.update(e),k.render(v,O)}var oe=new j["mb"];function ae(e){oe.x=e.clientX/window.innerWidth-.5,oe.y=e.clientY/window.innerHeight-.5}window.addEventListener("mousemove",ae);var ne,re,ie=0,ce=!1;function se(){for(var e=0;e<A;e++){var t=D.geometry.attributes.position.array;t[3*e+2]-=.001,t[3*e]-=.005,D.geometry.attributes.position.needsUpdate=!0}}function le(){ne=requestAnimationFrame(le),M.rotation.y+=.05,M.rotation.z+=.05,k.render(v,O)}function he(){requestAnimationFrame(he),$[0].rotation.y+=.2,$[0].rotation.z+=.2,$[1].rotation.y+=.2,$[1].rotation.z+=.2}function ue(){requestAnimationFrame(ue),F.rotation.y+=.01;var e={};e.x=oe.x,e.y=-oe.y;var t=.02;O.position.x+=(e.x-O.position.x)*t,O.position.y+=(e.y-O.position.y)*t,T.position.y=3*-ie/C.height,k.render(v,O)}window.addEventListener("scroll",(function(){ie=window.scrollY;var e=Math.round(ie/C.height);1!=e||ce||fe()}));var de=1,pe=.05,be=1;function me(){re=requestAnimationFrame(me),pe-=5e-4,q.scale.x+=pe*de,q.scale.y+=pe*de,q.scale.z+=pe*de,V.position.x-=.02*be,V.position.y-=.01*be,V.rotation.y+=.005*be,se(),V.position.x<-5&&(be=0),1==de&&q.scale.x>2&&(de=-1,O.rotation.x+=.1),-1==de&&(q.position.x-=.15,q.scale.x>500&&(ge(),cancelAnimationFrame(re)))}function ge(){requestAnimationFrame(ge),q.rotation.y+=1e-4}function fe(){ce=!0,ar.hideEntrance(),v.remove(F),v.remove($[0]),v.remove($[1]),v.add(q),me()}function je(){k.setSize(window.innerWidth,window.innerHeight),document.body.appendChild(k.domElement),k.render(v,O),O.position.z=5,le(),Z(),J(),U(),Q()}var ye=je,we={name:"App",components:{},data:function(){return{loadingProgress:0,loaded:!1,firstEnter:!0}},methods:{playMusic:function(){this.$refs.mbgm.paused?(this.$refs.mbgm.play(),this.$refs.playB.style.border="3px solid red"):(this.$refs.mbgm.pause(),this.$refs.playB.style.border="none")},toMyWorld:function(){var e=document.getElementById("mainView");e.scrollIntoView({behavior:"smooth"}),this.hideEntrance(),fe()},hideEntrance:function(){this.firstEnter=!1},checkRouteName:function(){var e=this.$router.currentRoute._value.path;return e}},mounted:function(){window.history.scrollRestoration="manual",window.scrollTo(0,0)}},ve=(o("9b1a"),o("6b0d")),Oe=o.n(ve);const ke=Oe()(we,[["render",f]]);var Te=ke,Ie=o("6c02"),Pe=function(e){return Object(a["w"])("data-v-108d408e"),e=e(),Object(a["u"])(),e},Ce={id:"Gallery"},Ae=Pe((function(){return Object(a["h"])("h2",{class:"GallerySubTitle"}," Digital Drawing & Design : ",-1)})),xe=["href"],Se=["src"],Ne=Pe((function(){return Object(a["h"])("h2",{class:"GallerySubTitle"}," 3D Modeling & Rendering : ",-1)})),Ge=["href"],De=["src"],We=Pe((function(){return Object(a["h"])("h2",{class:"GallerySubTitle"}," Video : ",-1)})),Ee=Pe((function(){return Object(a["h"])("ul",{id:"videoItem"},[Object(a["h"])("li",{id:"videoItem"},[Object(a["h"])("iframe",{width:"100%",height:"315",src:"https://www.youtube.com/embed/M-_IJ4WDqfY",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""})]),Object(a["h"])("li",{id:"videoItem"},[Object(a["h"])("iframe",{width:"100%",height:"315",src:"https://www.youtube.com/embed/nJyXYPPJaok",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""})]),Object(a["h"])("li",{id:"videoItem"},[Object(a["h"])("iframe",{width:"100%",height:"315",src:"https://www.youtube.com/embed/fQhPaQzmvVg",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""})])],-1)}));function Me(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",Ce,[Ae,Object(a["h"])("ul",null,[(Object(a["t"])(!0),Object(a["g"])(a["a"],null,Object(a["z"])(i.digitals,(function(e){return Object(a["t"])(),Object(a["g"])("li",{key:e},[Object(a["h"])("a",{href:e.original},[Object(a["h"])("img",{src:e.thumbs},null,8,Se)],8,xe)])})),128))]),Ne,Object(a["h"])("ul",null,[(Object(a["t"])(!0),Object(a["g"])(a["a"],null,Object(a["z"])(i.models,(function(e){return Object(a["t"])(),Object(a["g"])("li",{key:e},[Object(a["h"])("a",{href:e.original},[Object(a["h"])("img",{src:e.thumbs},null,8,De)],8,Ge)])})),128))]),We,Ee])}o("d81d");var Ve={name:"Gallery",data:function(){return{rootThumb:"/ImgThumbNail/",modelThumbs:["originAsteroid.jpg","starGas.jpg","normalAsteroid.jpg","scifi.jpg","m0.jpg","GNN.jpg","whiteDwarf.jpg","void.jpg","noise.png"],digitalThumbs:["backKnight copy.jpg","chaos.jpg","fuckFinal.jpg","wth.jpg","CSSGarden.jpg","Poster.jpg"],modeloriginals:["/ImgOriginal/originAsteroid.png","/ImgOriginal/starGas.png","/ImgOriginal/normalAsteroid.png","/ImgOriginal/scifi.png","/ImgOriginal/m0.jpg","/ImgOriginal/void1.jpg","/ImgOriginal/whiteDwarf.jpg","/ImgOriginal/void.jpg","/ImgOriginal/noise.png"],digitalOriginals:["/ImgOriginal/knightCombo.jpg","/ImgOriginal/chaos.jpg","/ImgOriginal/fuckFinal.jpg","/ImgOriginal/wth.jpg","https://bonnymidterm.glitch.me","/ImgOriginal/Poster.jpg"]}},computed:{models:function(){var e=this;return this.modelThumbs.map((function(t,o){return{thumbs:e.rootThumb+t,original:e.modeloriginals[o]}}))},digitals:function(){var e=this;return this.digitalThumbs.map((function(t,o){return{thumbs:e.rootThumb+t,original:e.digitalOriginals[o]}}))}}};o("2982"),o("2ed4");const ze=Oe()(Ve,[["render",Me],["__scopeId","data-v-108d408e"]]);var _e=ze,Ye={id:"AboutMe"},Re=Object(a["i"])('<h3><mark class="red">Name:</mark></h3><h3> 博尼 (Bonny Y. Wang) / 汪玥 (Yue Wang) </h3><h3><mark class="red">Affiliations:</mark></h3><h3> Center for Computational Astrophysics, Flatiron Institute (Guest Researcher) </h3><h3> The Cooper Union (Master Electrical Engineering Student) </h3><h3><mark class="red">Current Location:</mark></h3><h3> New York, NY </h3><br><h3><mark class="red">Contact:</mark></h3><h3 style="color:purple;"> wang27@cooper.edu </h3>',10),Le=[Re];function Be(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",Ye,Le)}var Ue={name:"AboutMe"};o("00c2");const Fe=Oe()(Ue,[["render",Be]]);var He=Fe,qe={id:"projectList"},$e=Object(a["h"])("h3",{class:"categoryTitle"}," Cosmology: ",-1),Je=Object(a["h"])("h2",null,"Machine learning cosmology from void properties",-1),Ze=Object(a["h"])("h3",null,[Object(a["j"])("arXiv:2212.06860 "),Object(a["h"])("br"),Object(a["j"])(" Submitted to ApJ")],-1),Qe=Object(a["h"])("p",{style:{"font-size":"15px"}},"Bonny Y. Wang, Alice Pisani, Francisco Villaescusa-Navarro, Benjamin D. Wandelt ",-1),Xe=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/web.jpg"},null,-1),Ke=[Je,Ze,Qe,Xe],et=Object(a["h"])("h2",null,"Graph Neural Networks for Voids",-1),tt=Object(a["h"])("h3",null,"Still in Progress...",-1),ot=Object(a["h"])("p",null,"Use GNN to Produce Cosmological Inference from Void Properties",-1),at=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/GNN.jpg"},null,-1),nt=[et,tt,ot,at],rt=Object(a["h"])("h2",null,"Data Visualization for Cosmic Voids",-1),it=Object(a["h"])("h3",null,"Still in Progress...",-1),ct=Object(a["h"])("p",null,"Use VR Technology to Create Immersive Scene for Cosmic Voids",-1),st=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/CosmicVoid.jpg"},null,-1),lt=[rt,it,ct,st],ht=Object(a["h"])("h3",{class:"categoryTitle"}," Game: ",-1),ut=Object(a["h"])("h2",null,"Worldmaking Class Blog",-1),dt=Object(a["h"])("p",null,[Object(a["j"])("A Class Blog Created for "),Object(a["h"])("i",null,"FA-327-1 Computational Studio: Simulated"),Object(a["j"])(" to Record My Journey in Virtual Worldmaking")],-1),pt=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/Noise.png"},null,-1),bt=[ut,dt,pt],mt=Object(a["h"])("h2",null,"Home Cat",-1),gt=Object(a["h"])("h3",null,"Available Online",-1),ft=Object(a["h"])("p",null,"A 2D platformer and simulation game about reviving people’s love by delivering cats in a cyberpunk world",-1),jt=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/HomeCat.jpg"},null,-1),yt=[mt,gt,ft,jt],wt=Object(a["h"])("h2",null,"Web AR for PurpleVerse in NFT.NYC",-1),vt=Object(a["h"])("p",null,"A Web AR Application for Augmented Exhibition Experience",-1),Ot=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/purpleLogo.png"},null,-1),kt=[wt,vt,Ot],Tt=Object(a["h"])("h2",null,"Space Persona",-1),It=Object(a["h"])("h3",null,"Available Online",-1),Pt=Object(a["h"])("p",null,"A Personality Game About Finding Your Position in the Space Mining Era",-1),Ct=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/spacePersona0.png"},null,-1),At=[Tt,It,Pt,Ct],xt=Object(a["h"])("h2",null,"Space Telescope Data Center",-1),St=Object(a["h"])("p",null,"A Web Platform for Showing Data Obtained by Yangwang-1 Satellite from Origin Space",-1),Nt=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/skyObserver.jpg"},null,-1),Gt=[xt,St,Nt],Dt=Object(a["h"])("h2",null,"Digital Logic Design: “Whac-a-Mole”",-1),Wt=Object(a["h"])("p",null,"A circuit designed with fundamental electronic components",-1),Et=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/DLDShow.jpg"},null,-1),Mt=[Dt,Wt,Et],Vt=Object(a["h"])("h2",null,"World of Gravity",-1),zt=Object(a["h"])("p",null,"A Game Created by to Explore the Effect of Gravity by N-body Simulation",-1),_t=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/gravityGame.jpg"},null,-1),Yt=[Vt,zt,_t],Rt=Object(a["h"])("h3",{class:"categoryTitle"}," Other: ",-1),Lt=Object(a["h"])("h2",null,"AI for Writing Chinese Poems from the Tang Dynasty",-1),Bt=Object(a["h"])("p",null,"Using the GRU architecture to Autogenerate Chinese Poems",-1),Ut=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/chinesePoem.jpg"},null,-1),Ft=[Lt,Bt,Ut],Ht=Object(a["h"])("h2",null,"PhotonLab Android App",-1),qt=Object(a["h"])("p",null,"Android App for Controlling the PhotonLab Smart Light System",-1),$t=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/PhotonLab.jpg"},null,-1),Jt=[Ht,qt,$t],Zt=Object(a["h"])("h2",null,"Smart Contract Vulnerabilities Detection",-1),Qt=Object(a["h"])("p",null,"A Program for Detecting Reentrancy and Unhandled Exceptions",-1),Xt=Object(a["h"])("img",{class:"projectImg",src:"/ImgThumbNail/smart.jpg"},null,-1),Kt=[Zt,Qt,Xt];function eo(e,t,o,n,r,i){var c=this;return Object(a["t"])(),Object(a["g"])("span",qe,[$e,Object(a["h"])("button",{onClick:t[0]||(t[0]=function(e){c.$router.push("/arXivMLVoid")}),class:"projectCard"},Ke),Object(a["h"])("button",{onClick:t[1]||(t[1]=function(e){c.$router.push("/Projects/GNN")}),class:"projectCard"},nt),Object(a["h"])("button",{onClick:t[2]||(t[2]=function(e){c.$router.push("/Projects/VRVoids")}),class:"projectCard"},lt),ht,Object(a["h"])("button",{class:"projectCard",onClick:t[3]||(t[3]=function(e){c.$router.push("/Projects/worldMaking")})},bt),Object(a["h"])("button",{class:"projectCard",onClick:t[4]||(t[4]=function(e){c.$router.push("/Projects/catHome")})},yt),Object(a["h"])("button",{onClick:t[5]||(t[5]=function(e){c.$router.push("/Projects/PurpleVerse")}),class:"projectCard"},kt),Object(a["h"])("button",{onClick:t[6]||(t[6]=function(e){c.$router.push("/Projects/SpacePersona")}),class:"projectCard"},At),Object(a["h"])("button",{onClick:t[7]||(t[7]=function(e){c.$router.push("/Projects/SpaceObserver")}),class:"projectCard"},Gt),Object(a["h"])("button",{class:"projectCard",onClick:t[8]||(t[8]=function(e){c.$router.push("/Projects/DLD")})},Mt),Object(a["h"])("button",{onClick:t[9]||(t[9]=function(e){c.$router.push("/Projects/GravityGame")}),class:"projectCard"},Yt),Rt,Object(a["h"])("button",{class:"projectCard",onClick:t[10]||(t[10]=function(e){c.$router.push("/Projects/ChinesePoem")})},Ft),Object(a["h"])("button",{class:"projectCard",onClick:t[11]||(t[11]=function(e){c.$router.push("/Projects/photonLab")})},Jt),Object(a["h"])("button",{class:"projectCard",onClick:t[12]||(t[12]=function(e){c.$router.push("/Projects/smartContract")})},Kt)])}var to={name:"Project"};o("5f9d");const oo=Oe()(to,[["render",eo]]);var ao=oo,no={class:"projectContent"},ro=Object(a["i"])('<h1 class="projectTitle"> Space Persona </h1><h2 class="projectSubTitle"> Created for Origin Space </h2><a href="https://bonnywang.github.io/spacePersona"><button class="playOnline"><b>Click Here to Play!</b></button></a><p style="color:aqua;"> (*Only available for mobile phones. If you do not have a mobile device with you, use the inspection mode of your browser and change the dimensions!) </p><h3 class="projectSubTitle"> A Personality Game About Finding Your Position in the Space Mining Era <br> Available in both Chinese and English </h3><h3> Background: </h3><p> According to the Kardashev scale, astronomer Carl Sagan believes we are still a Type 0.7 civilization. That means the energy we have exploited is very limited. While we have focused on using resources on Earth, there is much more we can explore in outer space. <br><br> Asteroids contain abundant resources like heavy metals, which are rare and hard to mine on Earth, but crucial for industrial uses. One single asteroid like 16 Psyche could be estimated up to 10 Quintillion dollars, more than the current global economy. NASA has planned the Psyche mission to study this particular asteroid. Asteroids in near-Earth orbits also contain tremendous values. <br><br> Space Persona would put you in a future era when space mining had become one of the major activities of society. By answering several dedicated questions, Space Persona would generate a specific guide based on your personality and help you find your way in the space mining era. </p><h3> Sample screenshots: </h3><img style="width:20%;" src="/ImgThumbNail/spacePersona.jpg"><img style="width:20%;" src="/ImgThumbNail/spacePersona_n0.jpg"><img style="width:20%;" src="/ImgThumbNail/spacePersona_q1.jpg"><img style="width:20%;" src="/ImgThumbNail/spacePersona_t0.jpg"><br><br>',14),io=Object(a["j"])(" There are also "),co=Object(a["j"])("Easter eggs"),so=Object(a["j"])(" in Space Persona designed for certain characters. Try to find them all! (*Hint: the rule is related to some sequences of dates.) "),lo=Object(a["h"])("h3",null," Sample Easter eggs: ",-1),ho=Object(a["h"])("img",{style:{width:"30%"},src:"/ImgThumbNail/spacePersona_s1.jpg"},null,-1),uo=Object(a["h"])("img",{style:{width:"30%"},src:"/ImgThumbNail/spacePersona_s0.jpg"},null,-1),po=Object(a["h"])("h3",null," Sample gameplay video: ",-1),bo=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/oca73-tzRVA",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1);function mo(e,t,o,n,r,i){var c=Object(a["A"])("large");return Object(a["t"])(),Object(a["g"])("span",no,[ro,Object(a["h"])("p",null,[io,Object(a["h"])("b",null,[Object(a["k"])(c,null,{default:Object(a["G"])((function(){return[co]})),_:1})]),so]),lo,ho,uo,po,bo])}var go={name:"SpacePersona"};o("01f1");const fo=Oe()(go,[["render",mo]]);var jo=fo,yo={class:"projectContent"},wo=Object(a["h"])("h1",{class:"projectTitle"}," World of Gravity ",-1),vo=Object(a["h"])("h2",{class:"projectSubTitle"}," Created to explore the effect of Gravity ",-1),Oo=Object(a["h"])("p",null," This is a game made with the Unity game engine to explore the amazing force in our world-Gravity. ",-1),ko=Object(a["h"])("p",null," When players click on the screen, a ball of random size, which represents an object with different mass, will be generated. The created object will then react to the gravity field generated by the rest of the objects in the scene. ",-1),To=Object(a["h"])("p",null," As you can see from the video below, the objects' amazing trajectories reveal the nature of our universe. ",-1),Io=Object(a["h"])("br",null,null,-1),Po=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/KMF9nGV43CU",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),Co=[wo,vo,Oo,ko,To,Io,Po];function Ao(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",yo,Co)}var xo={name:"Gravity Game"};const So=Oe()(xo,[["render",Ao]]);var No=So,Go={class:"projectContent"},Do=Object(a["i"])('<h1 class="projectTitle"> AI for Writing Chinese Poems from the Tang Dynasty </h1><h2 class="projectSubTitle"> Tensorflow RNN with GRU </h2><p> Github: <a href="https://github.com/BonnyWang/ECE467-Natural_Language_Processing/tree/main/3-Final_Project">https://github.com/BonnyWang/ECE467-Natural_Language_Processing/tree/main/3-Final_Project</a></p><h3> Sample Outputs: </h3><p> title:橫吹曲辭 巫山高<br> authors:杜甫<br> paragraphs:<br> 幽州意氣箕山坂，戰子三蕃阻鼠鞭。<br> 躍壁月中不改，金事不齊身。<br> 草木相微滿畫堂，繡蒿金縷繡林塘。<br> 琱青綺閣揖如已，一時榮落自君心。<br> 專詔燕樓崇已識，城梁和洗絕氛租。<br><br> title:橫吹曲辭 驄馬千堆<br> authors:郭震<br> paragraphs:<br> 隴火無氣色，山空髮盤乾。<br> 深沈不可巡，知食不能聽。<br><br> title:相和歌辭 大歌辭 鳳吹曲<br> authors:沈佺期<br> paragraphs:張說<br> paragraphs:<br> 鴛鴦夜白水驚碧，噴潤清笳簇金樞。<br> 綺房鶴容如不息，幽源今萬旗列出。<br></p><br><h3> Network Architecture: </h3><img src="https://miro.medium.com/max/1400/1*jhi5uOm9PvZfmxvfaCektw.png"><figcaption>Image Source: https://miro.medium.com/max/1400/1*jhi5uOm9PvZfmxvfaCektw.png</figcaption><h3> Description: </h3><p> The dataset for this project is obtained from https://github.com/chinese-poetry/chinese-poetry. In the JSON folder, Poet.tang.0.json, Poet.tang.1000.json, Poet.tang.2000.json, Poet.tang.3000.json are arbitrarily selected to be the datasets of the project. </p><p> Datasets are split into batches of size 64. In each batch, there is a pair of sequences of length 100 with one character shifted function as the input and the target(prediction). Since the task is generating text. There is no need for a testing dataset. However, the start phrase is chosen to be ‘title’ based on the format of the dataset and the anticipated format of the result. </p><p> As a person who did not have too much in-depth knowledge of Chinese poetry from the Tang dynasty, the result looks decent to me. Some of the sentences sound like a real poem. It also figured out the author correctly. Since the title and the name of the author have more clear patterns, the results for these two parts are generally reasonable. Most of the author names generated are actual authors instead of random names. Most of the titles are also similar to an actual title or is an existing title.<br><br> However, there are more problems the part of the paragraph. Usually, if most other sentences have the same size, there should not be an exception. We can see several outputs have different sizes for sentences. The last poem of the sample output also has “paragraphs:張說” followed by “paragraphs:” which is clearly not right. It could be inferred that the correct newline character is not generated and the “張” is a very typical last name so instead of a paragraph, the author name is generated. </p>',13),Wo=[Do];function Eo(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",Go,Wo)}var Mo={name:"ChinesePoem"};const Vo=Oe()(Mo,[["render",Eo]]);var zo=Vo,_o={class:"projectContent"},Yo=Object(a["i"])('<h1 class="projectTitle"> Yangwang-1 Space Telescope Data Center </h1><h2 class="projectSubTitle"> A Web Platform for Showing Data Obtained by Yangwang-1 Satellite from the Origin Space Company </h2><p> In collaboration with Zeyang Meng </p><p> The animation is based on the real orbit data of the satellite. </p><p> Screenshots: </p><img style="width:70%;" src="\\ImgThumbNail\\observer0.jpg"><img style="width:70%;" src="\\ImgThumbNail\\observer2.jpg"><img style="width:70%;" src="\\ImgThumbNail\\observer1.jpg"><br><p> Live Videos: </p>',10),Ro=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/Nzd00f4zRsA",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),Lo=Object(a["h"])("br",null,null,-1),Bo=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/olX8RoZDtDA",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),Uo=[Yo,Ro,Lo,Bo];function Fo(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",_o,Uo)}var Ho={name:"SkyObserver"};const qo=Oe()(Ho,[["render",Fo]]);var $o=qo,Jo={class:"projectContent"},Zo=Object(a["i"])('<h1 class="projectTitle"> Cosmic Voids Research </h1><h2 class="projectSubTitle"> Machine learning cosmology from void properties </h2><p style="color:#ff991c;"></p><p> Cosmic voids are the vast spaces between filaments in the universe that contain few or no galaxies. Their unique low-density property makes it easy to study and predict other hard-to-measure astrophysical parameters which would help scientists better understand the universe. </p><p> When it comes to processing voids’ data, typical statistical methods require large amounts of computational power. However, with machine learning, acceptable results can be obtained with limited resources and therefore speed up the study of the field. In particular, we found likelihood-free inference to be a promising solution to predict cosmological parameters using different statistics associated with voids like the void size function. </p><p> The cosmological parameters we aim to explore are Ω<sub>m</sub>, Ω<sub>b</sub>, h, n<sub>s</sub>, σ<sub>8</sub>, M<sub>ν</sub> and w. </p><p> Dataset Used: The GIGANTES dataset(Created by running the void finder VIDE QUIJOTE’s halo simulations.) </p><p> Previous study from Prof. Alice Pisani(We have successfully reproduced the following image): </p><img style="width:80%;" src="\\ImgThumbNail\\vsfParameter.jpg"><figcaption>https://arxiv.org/pdf/2107.02304.pdf</figcaption><p> Currently we want to explore the relationship between the voids&#39; ellip value and cosmological parameters. The following image indicate the relationship between cosmic voids&#39; radius and ellip values. </p><img style="width:50%;" src="\\ImgThumbNail\\ellipsevsR.jpg"><p> The moment network is aim to minimize the loss function: </p><img src="\\ImgThumbNail\\moment.jpg"><figcaption>Image Source: https://arxiv.org/pdf/2011.05991.pdf</figcaption>',15),Qo=[Zo];function Xo(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",Jo,Qo)}var Ko={name:"VoidsResearch"};const ea=Oe()(Ko,[["render",Xo]]);var ta=ea,oa={class:"projectContent"},aa=Object(a["h"])("h1",{class:"projectTitle"},"Data Visualization for Cosmic Voids",-1),na=Object(a["h"])("h2",{class:"projectSubTitle"},"Using VR Technology to Create Immersive scene for cosmic voids",-1),ra=Object(a["h"])("p",{style:{color:"#ff991c"}}," Still in Progress... ",-1),ia=Object(a["h"])("p",null," Headset Used: Vive Cosmos Elite ",-1),ca=Object(a["h"])("p",null," Dataset Used: The GIGANTES dataset(Created by running the void finder VIDE QUIJOTE’s halo simulations.) ",-1),sa=Object(a["h"])("h3",null," New Rendering Test in Unreal: ",-1),la=Object(a["h"])("iframe",{width:"80%",height:"315",src:"https://www.youtube.com/embed/y7V_Sb2uuVY",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),ha=Object(a["h"])("h3",null," Testing with the VR Headset: ",-1),ua=Object(a["h"])("iframe",{width:"80%",height:"315",src:"https://youtube.com/embed/lsgf39Zf7Is",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),da=Object(a["h"])("iframe",{width:"80%",height:"315",src:"https://youtube.com/embed/1GcwMccuWKE",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),pa=[aa,na,ra,ia,ca,sa,la,ha,ua,da];function ba(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",oa,pa)}var ma={name:"VRVoids"};const ga=Oe()(ma,[["render",ba]]);var fa=ga,ja={class:"projectContent"},ya=Object(a["i"])('<h1 class="projectTitle"> Home Cat </h1><h2 class="projectSubTitle"> Created during the 48-hour rct AI GAMEHACK 2021 and Won the Top Prize </h2><a href="https://bonnywang.github.io/GameHack2021/"><button class="playOnline"><b>Click Here to Play!</b></button></a><p> In collaboration with Yuqian Sun (Visual Artist), Enduro Wang (Developer), Hong Zhang (Visual Artist), Jiayu Wu (Musician), Morty (Developer) and Xuan (Desginer/Writer) </p><p>Github Repo Address: <a href="https://github.com/GameHack2021/GameHack2021-Unity">https://github.com/GameHack2021/GameHack2021-Unity</a></p><h3> Background: </h3><p> In the cyberpunk future world, you encounter a cat, a creature that hasn&#39;t been seen in a long time. You are attracted to its cute appearance. Therefore, you brought the cat to your home. You can only communicate freely with the cat through a translator at home. Due to the limitations of the translator, the conversations are not always logical. As you chat more with the cat, your feelings for the cat become stronger. However, because the cat generates so many kittens, you have to send the kittens to other people&#39;s homes. In the process of sending cats, you understand better the concept of home. From thinking that home was just a broken basement to a warm place you share with the cat. At the same time, you hope to let others feel the same healing effect that cats can bring, reviving people&#39;s emotions in this cold cyberpunk world. </p><h3> Technologies Used: </h3><p> Unity Game Engine and GPT-3 API <br><br> * The initial backend which connected to the rct AI&#39;s API is no longer available. GPT-3 is used instead for generating the cat&#39;s reply in the game. The use of GPT-3 enables full freedom of conversations with the cat. </p><h3> Core Loop: </h3><p> Chat to build up your connection with the cat -&gt; Go outside -&gt; Find doors to people&#39;s homes -&gt; Try to deliver kittens -&gt; Return to the first step </p><h3> Game concept art: </h3><img style="image-rendering:pixelated;" src="\\ImgThumbNail\\endCG.jpg"><img style="image-rendering:pixelated;" src="\\ImgThumbNail\\OpenCG.jpeg"><h3> Gameplay video: </h3>',15),wa=Object(a["h"])("iframe",{width:"80%",height:"315",src:"https://www.youtube.com/embed/Z7h5IpA_8do",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),va=[ya,wa];function Oa(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",ja,va)}var ka={name:"catHome"};const Ta=Oe()(ka,[["render",Oa]]);var Ia=Ta,Pa={class:"projectContent"},Ca=Object(a["i"])('<h1 class="projectTitle"> PhotonLab Android App </h1><h2 class="projectSubTitle"> Android App Developed to Connect and Control the PhotonLab Smart Lights </h2><p> Google play store: <a href="https://play.google.com/store/apps/details?id=xyz.photonlab.photonlabandroid">https://play.google.com/store/apps/details?id=xyz.photonlab.photonlabandroid</a></p><img style="width:20%;" src="\\ImgThumbNail\\photon2.png"><img style="width:20%;" src="\\ImgThumbNail\\photo1.png"><img style="width:20%;" src="\\ImgThumbNail\\photon3.png"><img style="width:20%;" src="\\ImgThumbNail\\photon4.png"><h3> Video for PhotonLab Light: </h3>',8),Aa=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/y5nYd6GKnjQ",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),xa=[Ca,Aa];function Sa(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",Pa,xa)}var Na={name:"photonLab"};const Ga=Oe()(Na,[["render",Sa]]);var Da=Ga,Wa={class:"projectContent"},Ea=Object(a["i"])('<h1 class="projectTitle"> Smart Contract Vulnerabilities Detection </h1><h2 class="projectSubTitle"> A Program for Detecting Reentrancy and Unhandled Exceptions </h2><p> Github Repo Address: <a href="https://github.com/BonnyWang/ECE455_CyberSecurity/tree/main/FinalProject">https://github.com/BonnyWang/ECE455_CyberSecurity/tree/main/FinalProject</a></p><h3> Background: </h3><p> As cryptocurrencies are gaining popularity and involving more capital, the related security issues need to be examined. We are especially interested in the possible vulnerabilities of the smart contracts on Ethereum used. Since smart contracts cannot be changed after their deployment, the integrity and security of the codes deserve more attention to be checked. This project tends to study two of the nine commonly known smart contract vulnerabilities: reentrancy and unhandled exceptions. The other seven common vulnerabilities – access control, arithmetic, denial of service, bad randomness, front running, time manipulation, and short address – are not discussed in the scope of this project due to our time constraints. We developed a program to test these two vulnerabilities for smart contracts and hope to protect them from related attacks. </p><p> As hundreds of different cryptocurrencies are gaining popularity, smart contract vulnerabilities begin to become a security concern. Once the smart contract is deployed on the Ethereum network, it cannot be changed. Therefore, analyzing them before the deployment is even more important compared to traditional programs. Reentrancy attacks are one of the common threats in the Ethereum blockchain. They are also the reason behind the famous DAO attack. The reentrancy attacks occur when an adversary leverages an external call of a smart contract. Due to certain patterns in the code, they can force the contract to execute additional code and utilize a fallback function to call back to itself. This could result in draining all the assets of one address. Another vulnerability we aim to detect is unchecked exceptions. Programmers too often assume the successful execution of the low-level functions that do not automatically interrupt the program execution on failure. The unchecked low-level call return values can lead to unexpected behavior in the program and could make it vulnerable to malicious users trying to tamper with the data. </p><h3> Instruction: </h3><p><u> Use the following line to install the library:</u><br> $ pip install nltk<br><u>To run the program:</u><br> $ python checkSmartContract.py<br><u>Sample outputs of the program:</u><br> $ python .\\checkSmartContract.py<br> Enter the smart contract you want to<br> check:reentrancy\\0x7541b76cb60f4c60af330c208b0623b7f54bf615.sol<br> Have reentrancy vulnerability!<br> Related Lines: 29<br> Vulnerable Functions: Collect<br></p><h3> Dataset Used: </h3><p> We are using the <a href="https://github.com/smartbugs/smartbugs/tree/master/dataset"> SB curated dataset</a> under the <a href="https://github.com/smartbugs/smartbugs">SmartBugs: A Framework to Analyze Solidity Smart Contracts</a>. It is a collection of vulnerable Solidity smart contracts organized according to the DASP taxonomy, containing 143 annotated contracts with 208 tagged vulnerabilities that can be used to evaluate the accuracy of analysis tools. </p><h3> Tech Analysis: </h3><p><u>Reentrancy:</u><br> The reentrancy attacks are mostly related to call function. Other functions like send and transfer are considered safer since they have a gas limit. There are two types of reentrancy attacks: single-function and cross-function attacks. A single-function attack occurs when the adversary attempts to recursively call the vulnerable function. A cross-function attack occurs when the target function calls another function that the adversary desires to exploit.<br><br> There are several steps used to detect the reentrancy vulnerability. The first step is to detect whether the call function is presented in the smart contract. If there is no call function used, then the contract would not be vulnerable to a reentrancy attack. Other conditions need to be further checked if the call function is present and the value is not set to zero. If the balance is deducted before the call function, then the function could be considered safe and resistant to reentrancy attacks. Another prevention for the attack is using a modifier that states the function can only be called by the smart contract owner. In this case, the function will be considered to be safe even if it uses the call function improperly. If no further protection is used for the call function, then the smart contract will be determined for having the reentrancy vulnerability and the function containing the call function will be marked the vulnerable function.<br><br> To further check the cross-function attack, the functions that call the vulnerable function will also be marked as the vulnerable function.<br><br><u>Unhandled Exceptions:</u><br> Unhandled exceptions, or in this case, we are potentially interested in unchecked return values for low-level calls – for low-level functions in Solidity like call(), callcode(), delegatecall(), and send(), as their executions fail, they will not propagate (or bubble up) and will not lead to a total reversion of the current execution – in other words, they would not throw an exception to interrupt the execution of the codes – these function would just return a false or a status code upon return. As they are simple functions, programmers usually would assume a successful execution; however, that’s not always the case – if the function fails and the return values are not checked, the failure will be ignored and the code will move on to the next step. The unhandled failure could lead to unexpected behavior of the program and make it possible for malicious attackers to potentially tamper with the data.<br><br> In Solidity, the most common methods of handling low-level function failures – the functions (like call(), calldata(), delegatecall(), and send() ) that would not propagate or bubble up, and would not lead to a total reversion of the current execution, but just return a boolean false on failure – is by the built-in functions like require(), assert(), and revert(). Alternatively, one can also utilize the try-catch feature, or go with the classic if statement. <br><br> To check for unhandled return values from low-level function calls, we simply filter out the lines of code that contains one of the known low-level functions, then parse through the line to check if any of the aforementioned methods are used to enforce the successful execution. Note that there is an edge case that would make this process a little bit troublesome – if the return value for a low-level call is stored in a local variable, then checked using if on the following line immediately. In this case, we would have to save the local variable name that contains the return value, and parse through the next line to see if there is an if statement – could also be a short notation – used to check the return status. We only parse the immediate next line to see if the return status is checked, because we do not want any other actions to take place in between the return of a low-level function and the checking of its return status.<br><br></p><h3> Reference: </h3><p> https://github.com/enzymefinance/oyente<br> https://github.com/smartbugs/smartbugs<br> https://dasp.co/<br> https://medium.com/coinmonks/protect-your-solidity-smart-contracts-from-reentrancy-attacks-9972c3af7c21<br> https://www.frontiersin.org/articles/10.3389/fcomp.2021.598780/full<br> https://github.com/Messi-Q/Smart-Contract-Dataset<br> https://github.com/tagupta/Reentrancy-attack/tree/main/contracts<br></p>',14),Ma=[Ea];function Va(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",Wa,Ma)}var za={name:"smartContract"};const _a=Oe()(za,[["render",Va]]);var Ya=_a,Ra=function(e){return Object(a["w"])("data-v-0dbe83bc"),e=e(),Object(a["u"])(),e},La={class:"projectContent"},Ba=Object(a["i"])('<h1 class="projectTitle" data-v-0dbe83bc> Digital Logic Design: “Whac-a-Mole” </h1><h2 class="projectSubTitle" data-v-0dbe83bc> A circuit designed with fundamental electronic components including timers, counters, flip-flops, decoders, and logic gates </h2><p data-v-0dbe83bc> In collaboration with Zikai Wang </p><h3 data-v-0dbe83bc> Overall circuits: </h3><img style="image-rendering:pixelated;" src="\\ImgThumbNail\\DLDWhole.jpg" data-v-0dbe83bc><h3 data-v-0dbe83bc> Introduction: </h3><p data-v-0dbe83bc> A Whac-A-Mole game that has 2 different levels of difficulties. There are six LEDs used to represent the six holes in the game. When the LED light up, it means the mole comes out of the hole and the user needs to press the corresponding button for a certain period of time depending on the level they choose to trigger the action of hitting the mole. If the user successfully hit the button while the LED is on, scores will be recorded and then displayed. In order to win, the user needs to hit 9 moles in 20 seconds. The 2 levels of difficulties will differ from the time you have to hit the mole. In level 2, the users need to hit the mole in a shorter period of time otherwise they cannot gain the score. To accomplish the goal of this project, we utilized timers, counters, flip-flops, decoders, and logic gates to achieve the logic behind this game. </p><h3 data-v-0dbe83bc>User Interaction:</h3><ul data-v-0dbe83bc><li data-v-0dbe83bc>Buttons(Corresponding to the Mole)</li><li data-v-0dbe83bc>LEDs to represent the Mole </li><li data-v-0dbe83bc>Button(To start the game)</li><li data-v-0dbe83bc>Switch(To change the difficulty of the game)</li></ul><h3 data-v-0dbe83bc>Mole Generator:</h3><ul data-v-0dbe83bc><li data-v-0dbe83bc>555 timer(Very High frequency)</li><li data-v-0dbe83bc>555 timer(Control how often one mole will come out)</li><li data-v-0dbe83bc>D flipflop(choose the number only when the clock signal of the second 555 timer is high)</li><li data-v-0dbe83bc>4-bit counter</li><li data-v-0dbe83bc>Decoder(the output)</li></ul><h3 data-v-0dbe83bc>Level Management:</h3><ul data-v-0dbe83bc><li data-v-0dbe83bc>Use of switch to change the capacity of the 555 timer to achieve different time period</li></ul><h3 data-v-0dbe83bc>Win Pattern Control(Game Cycle control):</h3><ul data-v-0dbe83bc><li data-v-0dbe83bc>SR latches(one for score counter, one for time counter)</li><li data-v-0dbe83bc>Button(To start the game)</li><li data-v-0dbe83bc>AND Gate</li><li data-v-0dbe83bc>LED(Represent the victory of the game)</li></ul><h3 data-v-0dbe83bc>Time Management:</h3><ul data-v-0dbe83bc><li data-v-0dbe83bc>555 Timer(period of 1s)</li><li data-v-0dbe83bc>4-bit counter</li><li data-v-0dbe83bc>2 Decoders</li><li data-v-0dbe83bc>2 Segment displays</li></ul><p data-v-0dbe83bc> Game play video: </p>',18),Ua=Ra((function(){return Object(a["h"])("iframe",{width:"80%",height:"315",src:"https://youtube.com/embed/0gD4PNapg4I",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1)})),Fa=[Ba,Ua];function Ha(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",La,Fa)}var qa={name:"DLD"};o("1c1c");const $a=Oe()(qa,[["render",Ha],["__scopeId","data-v-0dbe83bc"]]);var Ja=$a,Za={class:"projectContent"},Qa=Object(a["h"])("h1",{class:"projectTitle"}," Web AR for PurpleVerse in NFT.NYC ",-1),Xa=Object(a["h"])("h2",{class:"projectSubTitle"}," A web AR application for advanced virtual exhibition experience ",-1),Ka=Object(a["h"])("p",null," In collaboration with Mason Webb (Visual) ",-1),en=Object(a["h"])("h3",null," Mainview: ",-1),tn=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/EweZTT1ZY74",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),on=Object(a["h"])("h3",null," Backview: ",-1),an=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/tecee8YqSo8",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),nn=Object(a["h"])("h3",null," User Interaction: ",-1),rn=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/qqsmLcJe7Fg",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),cn=Object(a["h"])("h3",null," Object Enhancement: ",-1),sn=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/3_9cM_HKwcw",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),ln=Object(a["h"])("h3",null," Drawing and Commenting function: ",-1),hn=Object(a["h"])("iframe",{width:"60%",height:"315",src:"https://www.youtube.com/embed/IbTOC4OwvZE",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1),un=[Qa,Xa,Ka,en,tn,on,an,nn,rn,cn,sn,ln,hn];function dn(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",Za,un)}var pn={name:"purpleVerse"};const bn=Oe()(pn,[["render",dn]]);var mn=bn,gn=function(e){return Object(a["w"])("data-v-4ca00ccf"),e=e(),Object(a["u"])(),e},fn={class:"projectContent"},jn=gn((function(){return Object(a["h"])("h2",{class:"projectSubTitle"}," Use Graph Neural Networks (GNN) to infer cosmological parameters with void properties ",-1)})),yn=gn((function(){return Object(a["h"])("br",null,null,-1)})),wn=gn((function(){return Object(a["h"])("i",{class:"arrow down"},null,-1)})),vn=[wn],On=gn((function(){return Object(a["h"])("p",null," We use our current theories to create simulations and compare them to actual surveys. ",-1)})),kn=gn((function(){return Object(a["h"])("p",null," If actual surveys we got looks similar to our simulations, then we know we may be on the right path. ",-1)})),Tn=gn((function(){return Object(a["h"])("img",{src:"/ImgOriginal/SimVsSurvey.png"},null,-1)})),In=Object(a["j"])("What about the initial conditions for those simulations/models?"),Pn=Object(a["j"])(" Simulation-based Inference "),Cn=gn((function(){return Object(a["h"])("p",null," AKA Likelihood-free Inference ",-1)})),An=Object(a["j"])(" Use observation (output) of a simulation to infer it's initial parameter."),xn=Object(a["j"])(" Related works: "),Sn=gn((function(){return Object(a["h"])("p",null,[Object(a["h"])("a",{href:"https://arxiv.org/abs/2212.06860"},[Object(a["h"])("i",null,"Machine learning cosmology from void properties")]),Object(a["j"])(" arXiv:2212.06860 "),Object(a["h"])("br"),Object(a["h"])("small",null,"Bonny Y. Wang, Alice Pisani, Francisco Villaescusa-Navarro, Benjamin D. Wandelt")],-1)})),Nn=gn((function(){return Object(a["h"])("p",null,[Object(a["h"])("a",{href:"https://arxiv.org/abs/2212.06860"},[Object(a["h"])("i",null,"Learning cosmology and clustering with cosmic graphs")]),Object(a["j"])(" arXiv:2204.13713 "),Object(a["h"])("br"),Object(a["h"])("small",null,"Pablo Villanueva-Domingo, Francisco Villaescusa-Navarro"),Object(a["h"])("br")],-1)})),Gn=gn((function(){return Object(a["h"])("img",{src:"/ImgOriginal/graphGalaxy.jpg"},null,-1)})),Dn=Object(a["j"])(" https://arxiv.org/pdf/2204.13713.pdf "),Wn=gn((function(){return Object(a["h"])("ul",null,[Object(a["h"])("li",null," - The large under-dense regions in the Universe dominated by dark energy "),Object(a["h"])("li",null," - A novel probe for our understanding of the Universe "),Object(a["h"])("li",null," - Have proven to be sensitive to dark energy, modified gravity, neutrino mass and etc. ")],-1)})),En=gn((function(){return Object(a["h"])("img",{width:"200px",src:"https://www.researchgate.net/profile/Ebrahim-Yusofi/publication/354884627/figure/fig1/AS:1072905530126336@1632812020493/The-cosmic-web-is-mostly-occupied-by-vast-voids-The-bright-regions-are-clusters-and_Q320.jpg"},null,-1)})),Mn=Object(a["j"])(" https://www.researchgate.net/profile/Ebrahim-Yusofi/publication/354884627/figure/fig1/AS:1072905530126336@1632812020493/The-cosmic-web-is-mostly-occupied-by-vast-voids-The-bright-regions-are-clusters-and_Q320.jpg "),Vn=gn((function(){return Object(a["h"])("img",{style:{width:"100%"},src:"/ImgOriginal/GNNeq.jpg"},null,-1)})),zn=Object(a["j"])(" https://arxiv.org/pdf/2204.13713.pdf "),_n=gn((function(){return Object(a["h"])("img",{src:"/ImgOriginal/GNN1000voids.png"},null,-1)})),Yn=gn((function(){return Object(a["h"])("p",null," Using only 1000 voids from each catalog (the whole catalogs have 11,000 voids on average) ",-1)})),Rn=gn((function(){return Object(a["h"])("ul",null,[Object(a["h"])("li",null," - Use more voids "),Object(a["h"])("li",null," - Use different simulations "),Object(a["h"])("li",null," - Compare with the deep sets result "),Object(a["h"])("li",null," - Infer other parameters "),Object(a["h"])("li",null," - Discover new equations with symbolic regression ")],-1)})),Ln=gn((function(){return Object(a["h"])("br",null,null,-1)}));function Bn(e,t,o,n,r,i){var c=Object(a["A"])("big");return Object(a["t"])(),Object(a["g"])("span",fn,[Object(a["h"])("h1",{class:"projectTitle",ref:e.allrefs[0]}," Graph Neural Networks for Cosmic Voids ",512),jn,yn,Object(a["h"])("button",{onClick:t[0]||(t[0]=function(e){return i.scrollToElement()})},vn),Object(a["h"])("h3",{ref:e.allrefs[1]}," How do we study the evolution of our universe? ",512),On,kn,Tn,Object(a["h"])("h3",{ref:e.allrefs[2]},[Object(a["k"])(c,null,{default:Object(a["G"])((function(){return[In]})),_:1}),Pn],512),Cn,Object(a["h"])("p",null,[Object(a["k"])(c,null,{default:Object(a["G"])((function(){return[An]})),_:1})]),Object(a["h"])("h3",{ref:e.allrefs[3]},[Object(a["k"])(c,null,{default:Object(a["G"])((function(){return[xn]})),_:1})],512),Sn,Nn,Gn,Dn,Object(a["h"])("h2",{ref:e.allrefs[4]}," What are voids? ",512),Wn,En,Mn,Object(a["h"])("h2",{ref:e.allrefs[5]}," What is graph neural networks (GNN)? ",512),Vn,zn,Object(a["h"])("h2",{ref:e.allrefs[6]}," Current Result: ",512),_n,Yn,Object(a["h"])("h2",{ref:e.allrefs[7]}," What's next? ",512),Rn,Ln])}var Un={name:"GNN",data:function(){return{allrefs:["title","howStudyUniverse","SBI","related","void","GNN","results","next"],currentPtr:0}},methods:{scrollToElement:function(){this.currentPtr>=this.allrefs.length&&(this.currentPtr=0),this.$refs[this.allrefs[this.currentPtr]].scrollIntoView({behavior:"smooth"}),this.currentPtr=this.currentPtr+1}}};o("aa39");const Fn=Oe()(Un,[["render",Bn],["__scopeId","data-v-4ca00ccf"]]);var Hn=Fn,qn={class:"projectContent"},$n=Object(a["i"])('<h1 class="projectTitle">Worldmaking Class Blog</h1><h2 class="projectSubTitle">A Class Blog Created for <i>FA-327-1 Computational Studio: Simulated</i> to Record My Journey in Virtual Worldmaking</h2><h3> 01/26/2023 My Favorite Virtual World </h3><p><i>Ori and the Will of the Wisps</i> is a sequel to the phenomenal indie Metroidvania <i>Ori and the Blind Forest</i>. Compare to its previous version, its further improvement in immersion and flexibility made it the next milestone of its kind. <br><br><img src="https://assets.nintendo.com/image/upload/ar_16:9,c_limit,w_801/b_white/f_auto/q_auto/ncom/en_US/games/switch/o/ori-and-the-will-of-the-wisps-switch/hero"><br><br> Unlike other common 2D platformer games, <i>Ori and the Will of the Wisps</i> mixed 2D and 3D perspectives to create a more immersive scene for players. Although a player can only move in the XY plane, the background extends to the Z axis and is rendered in a 3D perspective. There are also shadows of plants and other creatures at the layer in front of the main ground, generating an illusion of peeking at the scene from another side of the forest rather than viewing an orographic close image through your monitor. <br><br> Besides creating this special angle of view for the game experience, <i>Ori and the Will of the Wisps</i> also utilize this feature to build more engaging Boss combats. All bosses are rendered in the 3D scene and gigantic in scale compared to Ori, creating a sense of oppression. When fighting Shriek, the player will see it initially as a small dot at the center of the screen since it is still far away, then rapidly approaching closer, taking up the most space of the screen and even shaking the entire scene. However, at the same time, this mix of perspectives could create some confusion for players. Since the collisions are still determined by overlaps in 2D, the motion curves of the skills and objects could be counter-intuitive. Personally, I only took a little time adapting it but it is something that could be improved by a better ordering of the object layers. <br><br><img src="https://i.ytimg.com/vi/vDdQg9WOZyk/maxresdefault.jpg"><br><br><i>Ori and the Will of the Wisps</i> also added diverse combat mechanisms and platform skills to enable a fluid, fast-paced and progressive game flow. Due to the high latency of Ori’s jump action, players are forced to accumulate more skills to pass different barriers on the map. In-air actions and skills like sliding, dashing, and bashing maximizes the possibilities of Ori’s movement and encourages its interactions with the physical elements in the environment. Noticeably, skills like bashing that have both effects in motion and attacking further make Ori’s combat experience flexible and allow players’ unique tactics for different enemies. <br><br> One thing I am personally sad to see is that <i>Ori and the Will of the Wisps</i> cancels the previous checkpoint mechanism. In Ori and the Blind Forest, players can only save their progress with energy cells or enter certain stages of the game. The balance between ability usage and game progress needs to be taken into extra consideration. Though it could be annoying if a player travels all the way to the other end of the map and forget to create a checkpoint by casting a skill, I still consider it a brilliant and novel design. However, <i>Ori and the Will of the Wisps</i> changes back to a traditional checkpoint solution, which is automatically saving progress when a player reaches a stable platform. I conjecture this adjustment is a compromise to the game’s difficulty. <br><br> Overall, <i>Ori and the Will of the Wisps</i> is another splendid piece by Moon Studios. By mixing 2D and 3D perspectives, adding more abilities and skills, and adjusting the game-saving mechanism, it reaches another level of captivation and versatility for 2D platform-adventure games. </p><h3> 02/02/2023 World Map Design </h3><p> A Planet Belongs to a Galaxy in a Void </p><img src="https://www.universetoday.com/wp-content/uploads/2008/07/void_eso_edit.jpg"><img src="/ImgOriginal/galaxyInsideVoid.jpg"><p> At local scale, we have other planets, asteroids and stars. </p><p> At large scale, we can go outside of galaxy or even outside of voids. </p><p> Question: scale, movement, spacetime </p><p> Movement reference: <br><br><img src="https://cdn.akamai.steamstatic.com/steam/apps/1138850/header.jpg?t=1639634527"><img src="https://www.notebookcheck.net/fileadmin/Notebooks/News/_nc3/planeten.jpg"></p>',12),Jn=[$n];function Zn(e,t,o,n,r,i){return Object(a["t"])(),Object(a["g"])("span",qn,Jn)}var Qn={name:"worldMaking"};const Xn=Oe()(Qn,[["render",Zn]]);var Kn=Xn,er=[{path:"/:catchAll(.*)",component:He},{path:"/Gallery",component:_e},{path:"/",component:He},{path:"/Projects",component:ao},{path:"/Projects/SpacePersona",component:jo},{path:"/Projects/GravityGame",component:No},{path:"/Projects/ChinesePoem",component:zo},{path:"/Projects/SpaceObserver",component:$o},{path:"/Projects/VoidsResearch",component:ta},{path:"/Projects/VRVoids",component:fa},{path:"/Projects/catHome",component:Ia},{path:"/Projects/photonLab",component:Da},{path:"/Projects/smartContract",component:Ya},{path:"/Projects/DLD",component:Ja},{path:"/Projects/PurpleVerse",component:mn},{path:"/Projects/GNN",component:Hn},{path:"/Projects/worldMaking",component:Kn},{path:"/AboutMe",component:He},{path:"/arXivMLVoid",beforeEnter:function(e,t,o){window.location.replace("https://arxiv.org/abs/2212.06860")}}],tr=Object(Ie["a"])({history:Object(Ie["b"])(),routes:er});ye();var or=Object(a["d"])(Te).use(tr).mount("#app"),ar=t["default"]=or},"5f9d":function(e,t,o){"use strict";o("eee1")},"63cd":function(e,t,o){},7387:function(e,t,o){},"9b1a":function(e,t,o){"use strict";o("bffe")},aa39:function(e,t,o){"use strict";o("49a7")},bffe:function(e,t,o){},db90:function(e,t,o){},eee1:function(e,t,o){}});
//# sourceMappingURL=app.2461de28.js.map